{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb40773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('./data/tests/test3.png')\n",
    "cv.imshow('image', img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "271c87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#cv.imshow('gray image', gray)\n",
    "\n",
    "# Optional: improve contrast\n",
    "gray = cv.equalizeHist(gray)\n",
    "\n",
    "# Threshold (adaptive) â€“ keep text white, background black\n",
    "thresh = cv.adaptiveThreshold(\n",
    "    gray, 255,\n",
    "    cv.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    cv.THRESH_BINARY_INV,\n",
    "    35, 10\n",
    ")\n",
    "cv.imshow('thresholded image', thresh)\n",
    "\n",
    "# Morphology to clean noise (larger kernel)\n",
    "kernel = cv.getStructuringElement(cv.MORPH_RECT, (3,3)) #bigger numbers add background blur\n",
    "morph = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations=1)  # remove specks\n",
    "morph = cv.morphologyEx(morph, cv.MORPH_CLOSE, kernel, iterations=1)  # connect strokes\n",
    "cv.imshow('morphological image', morph)\n",
    "\n",
    "# Use connected components instead of contours\n",
    "num_labels, labels, stats, centroids = cv.connectedComponentsWithStats(morph, connectivity=8)\n",
    "\n",
    "# Visualization\n",
    "vis = cv.cvtColor(morph, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "for i in range(1, num_labels):  # skip background\n",
    "    x, y, w, h, area = stats[i]\n",
    "\n",
    "    # Filter blobs (remove tiny specks and very large areas)\n",
    "    if area < 50 or w*h > 0.15*img.shape[0]*img.shape[1]:\n",
    "        continue\n",
    "\n",
    "    char_img = morph[y:y+h + 20, x:x+w]\n",
    "    cv.imwrite(f'results/char_{i}.png', char_img)\n",
    "\n",
    "    # Draw boxes for visualization\n",
    "    cv.rectangle(vis, (x, y), (x+w, y+h + 10), (0, 255, 0), 1)\n",
    "\n",
    "cv.imshow(\"characters\", vis)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process all of the tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847e3f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "###UTILITIES### NO NEED TO RUN THIS PART\n",
    "# Clean up: remove all files in the results folder after program ends\n",
    "# for f in glob.glob('results/*'):\n",
    "#     try:\n",
    "#         os.remove(f)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not remove {f}: {e}\")\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def clear_folder(folder_path: str):\n",
    "    \"\"\"\n",
    "    Clears all contents of the given folder but keeps the folder itself.\n",
    "    If the folder does not exist, it will be created.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Created folder: {folder_path}\")\n",
    "        return\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.remove(file_path)      # delete file or symlink\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # delete folder\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "    print(f\"Cleared contents of: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725f2300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared contents of: results\n"
     ]
    }
   ],
   "source": [
    "clear_folder('results')  # Clear the results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9160c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def recognize_character(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Receives an image path containing a single alphanumeric character\n",
    "    and returns the recognized character.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Restrict OCR to only alphanumeric characters\n",
    "    config = r'--oem 3 --psm 10 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'\n",
    "\n",
    "    char = pytesseract.image_to_string(img, config=config)\n",
    "\n",
    "    return char.strip()  # remove whitespace/newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fa7a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized character: t\n",
      "Recognized character: 2\n",
      "Recognized character: te\n",
      "Recognized character: \n"
     ]
    }
   ],
   "source": [
    "#First Test Successful\n",
    "result = recognize_character('./data/model-citizen/char_t.png') #letter recognized as t\n",
    "print(f\"Recognized character: {result}\") \n",
    "result = recognize_character('./data/model-citizen/char_2.png')\n",
    "print(f\"Recognized character: {result}\")  #letter recognized as 2\n",
    "result = recognize_character('./data/model-citizen/char_te.png')\n",
    "print(f\"Recognized character: {result}\")  #letter recognized as te\n",
    "result = recognize_character('./data/model-citizen/char_th.png')\n",
    "print(f\"Recognized character: {result}\")  #letter recognized as (none)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21c67160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d69d3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recognize_character' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m image_path = os.path.join(folder, filename)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# recognize character\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m char = recognize_character(image_path)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m char:  \n\u001b[32m     14\u001b[39m     char = \u001b[33m\"\u001b[39m\u001b[33mUNKNOWN\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# fallback if OCR fails\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'recognize_character' is not defined"
     ]
    }
   ],
   "source": [
    "folder = './results'  # folder containing character images\n",
    "results_paired = './results_paired'  # folder to save paired results\n",
    "'''results_paired folder stores directories named after the recognized character,\n",
    "each containing the recognized character image.'''\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):  # only images\n",
    "        image_path = os.path.join(folder, filename)\n",
    "        \n",
    "        \n",
    "        # recognize character\n",
    "        char = recognize_character(image_path)\n",
    "        if not char:  \n",
    "            char = \"UNKNOWN\"  # fallback if OCR fails\n",
    "        \n",
    "        # create subfolder for this character\n",
    "        char_folder = os.path.join(results_paired, char)\n",
    "        os.makedirs(char_folder, exist_ok=True)\n",
    "\n",
    "        # copy image into the character's folder\n",
    "        dest_path = os.path.join(char_folder, filename)\n",
    "        shutil.copy(image_path, dest_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40458d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clear_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m clear_folder(\u001b[33m'\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m'\u001b[39m)  \n\u001b[32m      2\u001b[39m clear_folder(\u001b[33m'\u001b[39m\u001b[33mresults_paired\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'clear_folder' is not defined"
     ]
    }
   ],
   "source": [
    "clear_folder('results')  \n",
    "clear_folder('results_paired') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b190946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"emnist_char_model.keras\")\n",
    "model = load_model(\"emnist_char_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45235b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"emnist_char_model\")\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load a sample image and preprocess it\n",
    "# # Mapping EMNIST labels to characters (62 classes: 0-9, A-Z, a-z)\n",
    "# # EMNIST ByClass mapping (example)\n",
    "# emnist_labels = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"  #0-10, A-Z, a-z\n",
    "\n",
    "\n",
    "# def predict_char(model, image_path: str):\n",
    "#     \"\"\"\n",
    "#     Given a trained model and a path to a character image,\n",
    "#     preprocesses the image and prints the predicted character.\n",
    "#     \"\"\"\n",
    "#     # Load and preprocess image\n",
    "#     img = Image.open(image_path).convert(\"L\")  # grayscale\n",
    "#     img = img.resize((28, 28))                 # resize to 28x28\n",
    "    \n",
    "#     img = np.array(img)\n",
    "\n",
    "#     # If your image has white text on black, invert it\n",
    "#     img = 255 - img\n",
    "\n",
    "#     # Normalize to 0-1\n",
    "#     img = img / 255.0\n",
    "\n",
    "#     # Add batch and channel dimension: (1, 28, 28, 1)\n",
    "#     img = np.expand_dims(img, axis=(0, -1))\n",
    "\n",
    "#     # Predict\n",
    "#     preds = model.predict(img)\n",
    "#     class_index = np.argmax(preds)\n",
    "#     predicted_char = emnist_labels[class_index]\n",
    "\n",
    "#     print(f\"Predicted character: {predicted_char}\")\n",
    "\n",
    "#See the image before prediction\n",
    "\n",
    "\n",
    "def predict_char(model, image_path: str):\n",
    "    \"\"\"\n",
    "    Given a trained model and a path to a character image,\n",
    "    preprocesses the image, shows it, and prints the predicted character.\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert(\"L\")  # grayscale\n",
    "    img = img.resize((28, 28))                 # resize to 28x28\n",
    "    img = np.array(img)\n",
    "\n",
    "    # --- REMOVE inversion if image is already white-on-black ---\n",
    "    # img = 255 - img  # Not needed\n",
    "\n",
    "    # Normalize to 0-1\n",
    "    img_norm = img / 255.0\n",
    "\n",
    "    # Show the preprocessed image\n",
    "    plt.imshow(img_norm, cmap='gray')\n",
    "    plt.title(\"Preprocessed Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Add batch and channel dimension: (1, 28, 28, 1)\n",
    "    img_input = np.expand_dims(img_norm, axis=(0, -1))\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(img_input)\n",
    "    class_index = np.argmax(preds)\n",
    "    predicted_char = emnist_labels[class_index]\n",
    "\n",
    "    print(f\"Predicted character: {predicted_char}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fa577f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_char' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predict_char(model, \u001b[33m'\u001b[39m\u001b[33m./data/model-citizen/char_S.png\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m      2\u001b[39m predict_char(model, \u001b[33m'\u001b[39m\u001b[33m./data/model-citizen/char_R.png\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'predict_char' is not defined"
     ]
    }
   ],
   "source": [
    "predict_char(model, './data/model-citizen/char_S.png')  # Example usage\n",
    "predict_char(model, './data/model-citizen/char_R.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c97ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec364d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
