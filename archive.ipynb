{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "# cv.imshow('gray image', gray)\n",
    "# gray = cv.equalizeHist(gray)\n",
    "\n",
    "# # Threshold (adaptive or Otsu)\n",
    "# thresh = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "#                                cv.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "# # Morphological operations to clean noise\n",
    "# kernel = cv.getStructuringElement(cv.MORPH_RECT, (2,2))\n",
    "# cv.imshow('thresholded image', thresh)\n",
    "\n",
    "# morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
    "# cv.imshow('morphological image', morph)\n",
    "\n",
    "# # Invert the binary image so characters are white on black\n",
    "# inverted = cv.bitwise_not(morph)\n",
    "\n",
    "# # Find contours (now characters are white)\n",
    "# contours, _ = cv.findContours(inverted, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "# cv.imshow('contoured image', contours)\n",
    "\n",
    "# # Extract and save each character bounding box\n",
    "# for i, cnt in enumerate(contours):\n",
    "#     x, y, w, h = cv.boundingRect(cnt)\n",
    "#     if w > 10 and h > 10:  # Filter small noise\n",
    "#         char_img = inverted[y:y+h, x:x+w]\n",
    "#         cv.imwrite(f'results/char_{i}.png', char_img)\n",
    "\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to train the model:\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load EMNIST (digits + letters)\n",
    "ds_train = tfds.load('emnist/byclass', split='train', as_supervised=True)\n",
    "ds_test = tfds.load('emnist/byclass', split='test', as_supervised=True)\n",
    "\n",
    "# Normalize images\n",
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "ds_train = ds_train.map(normalize_img).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(normalize_img).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Simple CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(62, activation='softmax')  # 62 classes (0–9, A–Z, a–z)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(ds_train, validation_data=ds_test, epochs=5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
